{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c86eae0-0e62-498a-a9cb-869c9f6f87fe",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770367460714}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "bronze_client=spark.table(\"bronze_client\")\n",
    "w_client=Window.partitionBy(\"CLIENT_ID\").orderBy(F.desc(\"ROW_UPDATE_DATE\"))\n",
    "silver_client=(\n",
    "    bronze_client\n",
    "    .withColumn(\"rn\",F.row_number().over(w_client))\n",
    "    .filter(\"rn=1\")\n",
    "    .drop('rn')\n",
    "    )\n",
    "\n",
    "SILVER_TABLE=\"silver_client\"\n",
    "#change all the date column to date type\n",
    "silver_client=(\n",
    "    silver_client\n",
    "    .withColumn(\"CLIENT_SERVICE_START_DATE\",F.to_date(\"CLIENT_SERVICE_START_DATE\"))\n",
    "    .withColumn(\"ROW_INSERT_DATE\",F.to_date(\"ROW_INSERT_DATE\"))\n",
    "    .withColumn(\"ROW_UPDATE_DATE\",F.to_date(\"ROW_UPDATE_DATE\"))\n",
    ")\n",
    "\n",
    "# if silver table does not exist, create one\n",
    "if not spark.catalog.tableExists(SILVER_TABLE):\n",
    "    (silver_client.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(SILVER_TABLE)\n",
    "    )\n",
    "\n",
    "#Merge:idempotent upsert\n",
    "silver_client.createOrReplaceTempView(\"silver_upsert\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "MERGE INTO {SILVER_TABLE} t\n",
    "USING silver_upsert s\n",
    "ON t.CLIENT_ID=s.CLIENT_ID\n",
    "WHEN MATCHED AND (\n",
    "    coalesce(s.ROW_UPDATE_DATE,s.ROW_INSERT_DATE)>coalesce(t.ROW_UPDATE_DATE,t.ROW_INSERT_DATE)\n",
    ") THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "INSERT *\n",
    "\"\"\")  \n",
    "#3)Check\n",
    "spark.sql(f\"SELECT COUNT(*) cnt FROM {SILVER_TABLE}\").display()\n",
    "spark.sql(f\"SELECT * FROM {SILVER_TABLE} ORDER BY ROW_UPDATE_DATE DESC\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_client",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
